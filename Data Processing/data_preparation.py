__author__ = 'adrianowalmeida'


import sys
from datetime import datetime
import traceback
from time import sleep

from util_sep.process_stack_xml import ConvertFiles, convert_csv_to_json
from apis import stack_overflow as so
import pandas as pd
from util_sep.util import dprint
from math import ceil
from glob import glob
import numpy as np
from os import path


VERBOSE = True

def split_user_files():
    '''
    Split user file by year
    '''
    user_file = '../Data/Users.xml'
    cf = ConvertFiles(user_file)
    cf.split_files_by_year()


def split_comments_files():
    '''
    Split comments file by year
    '''

    user_file = '../Data/Comments.xml'
    cf = ConvertFiles(user_file)
    cf.split_files_by_year()


def split_posts_files():
    '''
    Split post file by year
    '''
    user_file = '../Data/Posts.xml'
    cf = ConvertFiles(user_file)
    cf.split_files_by_year()


def split_votes_files():
    '''
    Split votes file by year
    '''
    user_file = '../Data/Votes.xml'
    cf = ConvertFiles(user_file)
    cf.split_files_by_year()


def get_users(p_amount=50000,p_page=0):
    '''
    Get the 50,000 more active users now and write to file
    :return: DataFrame with users
    '''
    # convert params to int
    amount = int(p_amount)
    page = int(p_page)

    api = so.StackSite()
    users = api.get_users(p_amount=amount, p_page=page)
    users.to_csv('users_{}k_from_{}.csv'.format(amount/1000, page), index=False, encoding='utf-8')
    return users



# python data_preparation.py get_top_users_tags 13500 14500
def get_users_tags(p_ini=None, p_final=1000, p_verbose=True, p_file='users_50k.csv'):
    '''
    Return the tags associated with the users

    Params:
    p_ini: the first user on the vector that should be brought
    p_fin: the last user that should be brought

    :return: data frame with all the tags
    '''
    # if here is no input, get the last files name as the init
    if p_ini:
        p_ini = int(p_ini)
        dprint('Starting from {}'.format(p_ini))
    else:
        file_list = glob('../Data/tags_top_*')
        last_users = []
        for n in file_list:
            info = n.split('_')
            last_users.append(int(info[3][:-4]))
        last_users.sort()
        p_ini = last_users[-1]
        dprint('Starting from last point {}'.format(p_ini))

    dprint('Fetching tags from {} users'.format(p_final))
    p_final = int(p_ini)+int(p_final)
    throttle = 1
    begin_time = datetime.now()

    # read the file with the users info
    users = pd.read_csv(p_file, encoding='utf-8', verbose=p_verbose)

    # get the first 1000 users tags, 100 by 100
    ids = users.user_id.unique()
    ids = ids[p_ini:p_final]
    loop_num = int(ceil((p_final-p_ini)/float(throttle)))

    # create an error output file as sometimes connection fails
    f_error = open('errors_tags_top_{}_{}.csv'.format(p_ini, p_final), 'w')
    error_count = 0

    # as we can only use for 100 users per time, 10 loops
    api = so.StackSite()
    first = True
    ret = None
    for i in range(0, loop_num):
        end = throttle + throttle*i
        ini = 0 + throttle*i
        if p_verbose:
            dprint("Fetching batch {} - {}/{}".format(i, ini, end))

        try:
            df = api.get_users_tags(p_client_list=list(ids[ini:end]))
            error_count = 0

            # concatenate the information
            if first:
                ret = df
                first = not first
            else:
                ret = pd.concat([ret, df])
                if p_verbose:
                    dprint('Final shape {}'.format(ret.shape))
        except:
            error_count +=1
            exc_type, exc_value, exc_traceback = sys.exc_info()
            msg = repr(traceback.format_tb(exc_traceback))
            f_error.write("Error batch {} - {} - {} \n".format(ini, end,msg))

            # when the problem begins, it does not stop. Quit trying
            if error_count>=10:
                break
            else:
                dprint('Sleeping 65 seconds')
                sleep(65)

    # write to output
    if p_verbose:
        dprint('Writing output file tags_top_{}_{}.csv'.format(p_ini, p_final))
    ret.to_csv('../Data/tags_top_{}_{}.csv'.format(p_ini, p_final), index=False,
               encoding='utf-8')
    f_error.close()

    # output the time it took
    if p_verbose:
        delta = datetime.now() - begin_time
        dprint('Time taken to process {:d}:{:d}'.format(delta.seconds/60,
                                                    delta.seconds % 60))

    return ret

def import_top_users_tags(file_pattern = None):
    '''
    Import the tags for the top 50k users generated by get_top_users_tags

    :param file_pattern: the directory and the file names pattern generated on
    the function get_top_users_tags
    :return: a dataframe with the tags
    '''
    if not file_pattern:
        file_pattern = '../Data/tags_top*.csv'
    files_list = glob(file_pattern)
    tags = None
    for f in files_list:
        dprint('importing file {}'.format(f))
        df = pd.read_csv(f)
        if isinstance(tags, pd.DataFrame ):
            tags = pd.concat([tags, df])
        else:
            tags = df

    if VERBOSE:
        dprint('Total tags loaded {}'.format(tags.shape))

    return tags


def deduplicate_tags():
    '''
    Get all the tags that have synonyms and apply the main tag


    :return:
    '''
    pass

def create_simple_files():
    # convert tags
    #cf = ConvertFiles('../Data/Tags.xml')
    #cf.create_simple_tags()

    # convert Users
    #cf = ConvertFiles('../Data/Users.xml')
    #cf.create_simple_users()

    # convert Posts
    cf = ConvertFiles('../Data/Posts.xml')
    cf.create_simple_posts()

    # convert Comments
    cf = ConvertFiles('../Data/Comments.xml')
    cf.create_simple_comments()

def create_model_input_csv(tag_cut,
                           output='../Data/Processed/model_input.csv'):
    '''
    Read the tags files, choose the most used tags, create a matrix of
    tags and users

    :params
        :tag_cut(in, optional): the limit of most points tags to be considered

    '''
    # convert param
    tag_cut = int(tag_cut)
    output = output.replace('.csv', '{}.csv'.format(tag_cut))

    # load tags, sum the points and find the top tag_cut
    if VERBOSE:
        dprint('Starting - create model input')
        dprint('reading data and getting top {} tags'.format(tag_cut))
    tags = import_top_users_tags()
    tags_count = tags.groupby(['name'])['count'].sum()
    top_tags = tags_count[tags_count.rank(ascending=False)<=tag_cut].index

    # filter data with only the top tags
    top_tags_data = tags[tags.name.isin(top_tags)]
    if VERBOSE:
        total_top_tags = len(top_tags_data.name.unique())
        total_top_users = len(top_tags_data.user_id.unique())
        dprint('After filtering: Total Tags:{} , Total Users: {}'.format(total_top_tags,
                                                       total_top_users))

    # widen the tag and create a sparse matrix.
    if VERBOSE:
        dprint('Creating sparse matrix')
    top_tags_wide = top_tags_data.pivot_table(['count'], index=['user_id'],
                                              columns=['name'],
                                              aggfunc=lambda x: np.sum(x))
    top_tags_wide = top_tags_wide.fillna(0)
    top_tags_wide.columns = ["{0}".format(l2) for l1, l2 in top_tags_wide.columns]

    # save the file
    if VERBOSE:
        dprint('Saving file {}'.format(output))
    top_tags_wide.to_csv(output, index=True)
    if VERBOSE:
        dprint('Finished')

def create_json_files():
    '''
     Convert all csv to json so that we can import to a json database
    '''
    # get all files on the processed directory
    f_list = glob('../Data/Processed/Simple*.csv')
    for file in f_list:
        file = path.abspath(file)
        out = file.replace('.csv', '.json')
        if VERBOSE:
            dprint('Converting {} to {}'.format(file, out))
        convert_csv_to_json(file, out)
        if VERBOSE:
            dprint('Finished processing {}'.format(file))


def _usage_and_exit():
    print "Usage: {} function-name [arg1 [arg2 ...]]".format(sys.argv[0])
    sys.exit(0)


if __name__ == '__main__':
    if len(sys.argv) == 1:
        _usage_and_exit()

    func = globals().get(sys.argv[1])
    if func is None:
        _usage_and_exit()

    func(*sys.argv[2:])
    #get_top_users_tags(0,3)